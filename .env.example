# LLM Configuration
LLM_PROVIDER=aws # Options: aws, openai, anthropic, azure, etc.
# Set the base URL for the LLM provider if required
# For AWS, this is typically not needed as it uses the default endpoint
LLM_BASE_URL=
LLM_API_KEY=your_api_key_here # For OpenAI or other LLM providers
# Choose the LLM model o4-mini, gpt-4o, etc.
LLM_CHOICE=

# AWS Configuration
AWS_REGION=us-east-1
AWS_ACCESS_KEY_ID=your_access_key
AWS_SECRET_ACCESS_KEY=your_secret_key

# Obsidian MCP Server Configuration
OBSIDIAN_VAULT_PATH=/path/to/your/vault
OBSIDIAN_DAILY_NOTES_PATH=Daily Notes
OBSIDIAN_TEMPLATES_PATH=Templates

# SearXNG MCP Server Configuration
SEARXNG_BASE_URL=http://localhost:8080
SEARXNG_API_KEY=your_searxng_api_key

# Todoist MCP Server Configuration
TODOIST_API_TOKEN=your_todoist_api_token
TODOIST_PROJECT_ID=your_default_project_id

# YouTube MCP Server Configuration
YOUTUBE_API_KEY=your_youtube_api_key # Optional
YOUTUBE_TRANSCRIPT_LANGUAGE=en

# Optional: Development & Monitoring
LOG_LEVEL=INFO
LANGFUSE_SECRET_KEY=your_langfuse_secret_key
LANGFUSE_PUBLIC_KEY=your_langfuse_public_key
LANGFUSE_HOST=https://cloud.langfuse.com
DEBUG_MODE=false

# Optional: GUI Configuration
GUI_THEME=default
GUI_PORT=7860
GUI_SHARE=false